M: I want to start with you, Amy, because I know you obviously at Shell have had AI as part of the working process, creating efficiencies, a number of different use cases, you're using it to kind of transcend as well, at least do the transformation away from some of the the the carbon parts of the business towards that green evolution and you see that as consequential. How do you look, how do you assess what the needs are and then isolate and focus on the potential solutions before we get onto the question of how you incorporate that? How do you how do you how do you zero in on where the needs are across the business?
R: I think it's like with any um improvement initiative, you're going to have have a lot of different ways you look for ideas and you can do them top down, you can do benchmarking, you can say where have we got high areas of cost. Um, what's your intuition? What what what did you learn in your last business and you can do it bottom up as well, where you ask the machine operator, how is this process stupid? How could you do better? Also, you look for any kind of very manual process or something which is very um, tricky or often goes wrong. Um, I think the trouble is there's opportunity everywhere. The only difference is how much value it is. So once you've got your kind of long list of ideas or areas you think you could look at, it's then a question of your standard two by two matrix of feasibility, um, how easy is it versus value? And that's the piece we use to to from the beginning say, do we think this is worth looking at? And then as we go through, as we learn more about the problem, you'll find out actually it's harder than you thought, or it's easier than you thought or the value isn't there for some reason. And then you adjust. But basically, it's the usual, I don't actually think it's that different from any other lever you can pull in business in terms of process redesign and the rest of it, because it's also it's not just about efficiency, often it's a quality thing as well. If you want to improve customer service, you don't just want to talk to more customers in an hour and treat more of them. You also want to provide a better service, make sure you answer their query quickly. But fairly standard.
M: Is it is it a harder sell to the board because of the some of the unknowns around at least the new generative parts of AI.
R: The generative AI. Or do you get it across the board as easily as you would any other potential. It's an interesting one because I think with AI and particularly generative AI, you have your usual problem of AI, which is on the one hand people think it's magic.
M: Yeah.
R: Magic is an easy sell. On the other hand, you have to deliver to magic and that's not easy. So it's always this mix of you have to do a certain amount of marketing. You have to tell people what we can do genuinely if you haven't seen it before. This is the amazing stuff we can do, but also set expectations that this isn't magic. It's hard work, it often fails. It requires just as much process change um, change management, impact from the business as anything else. Um, and that's a very balanced message, but I've certainly found um, with our leadership there's a lot of receptivity and it's there's a lot of excitement at the moment.
M: Tony, let's bring you in at this point. Cloud services, the cloud essential to what what you do and Temenos recently launching an AI power product as well for transactions. So to make it easier for your clients, financial services and banking clients to be able to to kind of put out at least monitor and give detailed information on on on transactions for for their clients and their customers as well. How how do you identify the need? How have you been thinking about this and some of the potential pitfalls and opportunities around how to implement?
R: Yeah, I think to to build on what Amy was saying, it's it's a lever, right? And we were joking just before in the over coffee that the the answer is generative AI. Now, what's your problem? Yeah. Um, and that that's a pitfall. Um, so we're at Temenos we're a big fan of appropriate use of technology. Um, and that can be the pragmatic stuff. Um, a lot of it, again, building what Amy was saying, is around not only the AI elements, the culture and the organization as well. You're you are changing people's jobs, that's part of that's part of what we're doing. And hopefully for the better. Um, and so when you look at things like, you know, transaction classification is not new. We've been doing it for years and years based off, you know, originally rules then traditional AI, if I can say that at this point, um, and then moving into explainable AI and now generative AI. So it's layering on these tools and techniques, coupling it with the the culture change and the the underlying organization change that you need as well.
M: Does that ring true with you, Alex at Accardo?
R: Uh, absolutely. Uh, Accardo, we really first look at the business end to end, understand the operating costs uh, of our retail partners. So Accardo, we are no longer Accardo retail. Uh, we own 50% of Accardo retail along with M&S. Uh, Accardo's business today is in providing an end-to-end e-com grocery logistics platform for international retailers all over, so Kroger, Coles, Aon, uh to name just a few. Uh, and teams that work for me and across Accardo technology, we focus really on understanding uh the customers, the customer's business model. And so, you know, last mile logistics is a very significant uh proportion of sales in terms of the cost, as is

--- NEXT SEGMENT ---

M: the customer's business model. And so, you know, last mile logistics is a very significant uh proportion of sales in terms of the cost. Uh as is uh operating the warehousing, the logistics. And so that's where we really focus an awful lot of our innovation uh is in these two areas are very high cost for retailers to operate uh a logistics platform. Uh but we need to have uh machine learning and AI pervasive through the end-to-end capability in order to be able to realize those sort of incremental gains that really lead to fundamentally either having a profitable business or not because of, you know, how uh thin the margins are in grocery. And so, uh you know, interaction from the web shop through to the warehouse, supply chain, routing systems all the way to last mile growth logistic, delivery, uh have to be very tightly coupled together. Uh and insights from one have to be fed through and so, you know, customer customer shopping habits uh influence how we design warehouses. Um and then all the way through into using AI uh to do things like picking and packing, which is what my team's do at the moment. Uh all the retailers around the world range different items uh in the UK. They range 70,000 different types of items and so the diversity and complexity is huge. There's no way you can build systems using traditional technologies and heuristics. One really has to embrace uh systems that learn from data uh such as AI and doing that by really focusing the investment where it generates that return.
M: How how do you decide whether to build in-house or to buy in or pull in third parties?
M: Uh so Acardo in effect is monetizing its intellectual property and so we have to be very careful about how we use third-party technology uh in the way that it's licensed. But we leverage an awful lot of common AI technology and tooling such as Tensorflow. Uh a few years ago we were working on a project to uh predict the failures in some of our bit of actual automation, physical automation. Uh my came back from aerospace a few years ago. And so we leverage something called Google WaveNet, which was a machine learning capability developed by Google for time domain signals. Uh it was traditionally developed for uh speech recognition, but you are able to adapt this technology for learning any time domain signal and then uh you know, if you are uh in the process of physical automation, motors, sensors, these all generate time domain uh data streams and so we leverage things like uh WaveNet. And then we build our own the latest control system that we have uh leverages a different type of generative AI, not language on, uh but actually it's called behavior cloning, where we use the cognitive ability of humans to effectively remote control the robots to start with. Uh we then use that data to train the AI and it is end-to-end, right? So video comes in, uh robot control comes back out, and the ability of these systems to generate uh to to generalize across problems they haven't seen is phenomenal. I mean it's just it truly blows my mind in terms of the capability.
M: So that there's the human training element and then the human step back, steps back and they're able to functions.
M: But AI isn't perfect. AI goes wrong and so how we leverage humans and I working collaboratively together. Uh if the robot for whatever reason is unable to complete a pick, uh maybe it drops an item, you know, packaging has changed, packaging has been damaged or something, uh then we're able to use uh remote operators to effectively collaborate with the AI to help complete the task. So it uh performs operational recovery uh in order to maintain that kind of very reliable uh service that we need 24/7, picking millions of items a day. Uh and then we can use the data from a failed pick that has been recovered by this remote pilot to go and improve the AI over time. And so having a strategy where you build technology that for us this remote operation stuff, it helps us build the ML at the beginning. Uh it helps us operate it in terms of the the real world operational challenges and then that it also helps us kind of build further improvements and so you're kind of you know, uh generating inertia in this flywheel that gets faster and faster and faster.
M: There's a combination then of in-house solutions and third parties. when it comes to you.
M: What about at Shell Amy? How do you think about whether to build it out in-house? Do you have the resources? Do you have the team and you've got your cash rich company? Do you do it in-house or do you do you pull in third parties?
R: I think similar to Alex. I don't think anyone could say they're building everything in-house nowadays because your component parts, the component parts you get from outside are just so good now, you'd be crazy to try and do it on your island. But I mean we always think in terms of is it our core IP? What are we? We are, we produce energy, we process it, we um distribute it and we trade it. That's core to what we do. And if it's something outside of that, which isn't completely easy or obvious or anything like that, then we should use market standard. And if it's something within that, then we might want to look carefully at whether it's our core IP and therefore we want to keep it. I think build versus buy is a bit simple though because there's plenty of things like partner or build on something that's actually third party. And obviously we we use um cloud platforms, like everyone else. We're not going to try and use our component parts. So actually it's it's always a patchwork of taking what you have from the market, building on what

--- NEXT SEGMENT ---

M: cloud platforms, like everyone else. We're not going to try and use our component parts. So actually, it's it's always a patchwork of taking what you have from the market, building on what you need internally, and just being really clear about how best to use your time and resources.
M: How do you find are there frictions when it comes you think of an oil company or an energy company like Shell, and you think of engineers out there on rigs. You have those engineers, but you also have your software engineers building out some of these AI solutions. How do you meld the two? Is there a friction there? How do you get past that?
R: That's a different type of friction. I mean, I I don't see that so much with the front line necessarily. That's always a change management question that you're with any population, whatever it is, whether it's call center workers or people on an oil rig. It's always going to be some people think, brilliant, let's try something new. Let's see how we can do this differently. Some people are like, I don't know. It's worked so fine fine so far for 25 years. Why change it? And other people are kind of could go either way. So it's always an effort to to really do the change management, make sure everyone's bought in, make sure it's explained properly, make sure it is to everyone's benefit as well. Of course, people don't want to adopt things which they're not sure about. But I mean, that's a very different type of tension, I think, and that's one which again is no different from any other process change, any other change to a business that you'll have.
M: Tony, is it is it is it easier for you because you're a pure software play? Maybe you don't have those same I mean, you're smiling at this, so maybe maybe those tensions don't exist. How do you how do you once you've decided, you've selected what the problem is, you've chosen whether you're going to do it in house or pull in a third party, make an acquisition, you've found out what the solution what what you the problem you're trying to tackle is and then you have a team tackle it with that particular solution. How do you embed that then into the business and mitigate the downside risks?
R: So, I think you've been reading some of our blog posts because the keyword there is embed, right? So, so yes, much and again to to not necessarily just say yes us as well. But um, yeah, we take a mixed approach. We're not going to build out the nuts and bolts. There's a great deal of open source out there that we want to use and again partnering is uh is another angle. But then um, you know, pulling it all together is where it starts to the magic happens as it were.
R: So, in terms of what we try to do and we try to encourage our clients, the banks to do as well, is not sort of put AI over there in a corner. We want all of our product managers, all of our product teams, all of our engineering teams to be able to use this platform capability, which, you know, we may well change over time and that's fine. That's why we put a platform over the top of it, so that they can then build our core IP banking IP over the top of those models, over the top of those capabilities, regardless of what the underlying AI tech is. So it's about exactly that, embedding it into the teams, embedding it into the products. That's how we've seen a lot of our customers be successful and that's how we're rolling out our AI powered products as well.
M: A lot of this innovation is obviously happening far ahead and moving far more quickly than the regulators are. And you work obviously in a very regulated space. So how how do you how do you keep ahead of your competitors whilst also assuring ensuring that you don't fall foul of the regulators?
R: So one of the things that we talk about a lot is this concept of responsible AI. And, you know, previously we talked about um explainable AI and ethical AI. So we kind of roll it all together into this concept of responsible AI. And again, we were talking at the break about how we can see legislation coming down the track. We know it's coming. But moreover, um it's a duty of care if you will, so that if somebody um has a loan application rejected, they need to understand why. You can't be using black box models that just, you know, computer says no, you need to understand why, you need to be able to challenge that and you need to provide evidence that if it is behavior based, so again at the break we were talking about the idea that perhaps as a as an SME as a a leader in a small company, you may not get a loan because your cholesterol is high. But unless you know that's what the problem is, then you don't have a way of fixing it and you don't have a way of challenging it.
R: So, yes, there's all this regulation coming down the track, keeping an eye on it, looking to the wider industry, obviously, but also a lot of that regulation, hopefully, maybe this is a little um a little optimistic, is there to protect the consumers and ourselves. So really, you know, come back to do what's what's good, what's correct um is is the the north star if you will.
M: Okay, so the importance of explainable models versus some of the black box. Absolutely. So maybe a bit of a critique of of Chat GPT and Open AI on that level. there's a question actually from the audience around what your use is of of Open AI. So get to that very shortly. Uh but Alex, on on the question of of regulation on the question of data. Obviously, your clients are customer facing. I may not want your clients to know that


--- NEXT SEGMENT ---

M: We'll get to that very shortly. But Alex, on on the question of of regulation, on the question of data. Obviously, your clients are customer facing. I may not want your clients to know that on a Friday I buy 10 tubs of ice cream and a bottle of whiskey. So how do you think about data and abuses of data and how to put ring fence that so that you don't lose that client trust?
R: Ah, so again, we have a responsible, uh, AI policy that is being heavily influenced. No, we don't. clients to be tracked for data and ensure the lack of biases.
Uh, fundamentally, in terms of your question, how do we ensure that kind of confidence from our retail partners? We don't track uh, individual people, basically, right? They they hold all of that data in their own systems and what we get is effectively tokenized and anonymized data so that we can use that to improve the systems without having any access to uh any individual customers.
M: So do you use, on this question that's come through from from one of our viewers or someone in the room, Open AI, do you use it in your systems?
R: Uh, not within our systems. Uh at the moment sort of uh the free to use chat GPT, everything that you put into it is public domain. And so we are being very careful about how we do use it. However, our teams are of engineers do leverage it as part of supporting them doing their work. Uh, I have a team of engineers 3D printing a robot arm. Uh and actually we were uh exploring different permutations of which print technology in order to drive cost and the right kind of mechanical performance. And so we leverage chat GPT to uh explore different permutations with different types of print technology by posing it a series of questions. Uh it came back with the answers in a split second. We validated a number of them for accuracy, they were 100% accurate and then we just believe the rest, I'm afraid. Uh so as a support tool, if you understand how to write the right query.
M: Yeah.
R: Uh, it is incredibly powerful.
M: Next time, bring the arm in with you.
R: I will happily do that.
M: Okay, so you use chat GPT for the hallucinations, you stress test for some of those. Amy, you use, you've allowed chat GPT4 to be used at Shell.
R: Not me personally, but yeah. Okay.
Some some some institutions, some banks, for example.
R: Yeah, you know, we certainly are using um well, we haven't actually blocked um public chat GPT yet. It's we've trained people, but we haven't blocked that. But more importantly, we are using the APIs by Microsoft on Open AI, on Chat GPT, um to create services in Shell and to run a series. We've got a whole program um using that and other generative AI models, both in vision and text to explore what we can do around the business to improve efficiency, for sure, but uh also look at quality and other impacts. So we do have a large generative AI program now.
M: Okay. Uh, another question coming through from the audience. Where do you see the trend of automation going, especially when we're influenced by chip shortages and AI enthusiasm? Tony, let's put that question to you. And video was very much in the headline the last few weeks. Some of their most high-end chips cost about 20-30,000 US dollars. We have a shortage of them here in the UK. What what is your take on that question?
R: So, to an extent, the answer's cloud. Now, at the at the risk of coming back to the nuances, the answer's cloud now. What's your problem?
M: You should have sold it.
R: Um, you know, the ability to put a pragmatic use of technology, putting the right workloads on the most efficient chips. Cloud gives you that ability. Most banks typically for historic reasons will have an amount of tin that they can reuse. It's unlikely they've got vast amounts of GPUs or AI friendly kit lying around. So um and you know, in 2023, do you want to be building that? Now, there's um my friends at IBM, uh we've had a few discussions on this and the idea of a hybrid cloud where some of our customers, some of our banks need to keep this data on Prem or want to for whatever reasons. Um then, you know, there's a different set of chip technology that they can bring to bear there. So, cloud, but hybrid. Um, so yeah, a combination of those two, again appropriate technology for the right for the right use case.
M: Alex, are you project out five years, where do you see automation taking us as we weigh up these two it seems conflicting pressures, the shortage of chips and this hype and enthusiasm around AI.
R: Uh, in the space that we operate. I mean I see it becoming ever more efficient our operation uh for the retailers that we support fundamentally and without going to a different challenging question about AI and jobs. Uh, the main uh direct cost that our retailers faced is uh, you know, fairly low skill labor roles, whether they are picking and packing in a warehouse or doing other types of handling.
M: But we'll have jobs, aren't they?
R: I I'm afraid, I kind of think that at some point in the event horizon they are. Uh moving in uncertain environments if you're on a road is much more complicated than handling things in a warehouse, which is where we are focusing at the moment. Uh, when it comes to the challenge and constraints of chip availability. Actually, Adacado years ago, we uh encountered our threshold of how much spend we are willing to make in terms of cost for cloud costs and so.

--- NEXT SEGMENT ---

M: 30 actually. Adacaro years ago we uh encountered our threshold of how much spend we are willing to make in terms of cost for cloud costs. And so today, uh we are very conscious when we build new systems about the amount of logging that we're creating, the amount of data that we're storing, uh our ability to generate data versus the utility we get from that data. It far exceeds the potential benefits. And so actually having a very strong focus on how you maximize your utility from data, uh which therefore ultimately ends up meaning we have to be quite efficient with the hardware that we're using. When we deploy robots, uh the robots need to be for a certain price point and so I'm afraid we can't deploy them with just like tens of GPUs. And so actually we have to find ways of deploying uh very advanced physical automation systems and also software-based automation systems uh that don't just consume uh all the computer that you can throw at it. So actually, being very efficient with data and then which means being efficient with compute at the same time is key.
M: Amy, how much uh free rein do you have to spend on compute? Are you are you concerned that the the lack of compute, uh the shortage of chips, the cost could could hold back some of these innovations?
R: Uh, yes. Um, I think the supply chains currently are very fragile and there are efforts being made to make them more robust with government support in various countries. That will take some time to flow through. So I think the combination of the absolute hype and the fragile supply chain could lead to a bit of a crunch. Whether that's actually going to impact everyday operations, I'm not sure because these things take time to develop and really put into practice anyway, but that definitely is a concern.
M: There's another question coming in about quantum computing and the impact on the pace in terms of how quantum computing might may speed up the implementation of AI. Anyone kind of jumping out with a view, a strong view on that?
R: I think it'll take some time.
M: It'll take some time.
R: Yeah. Still a ways out.
R: We have a researcher dabbling occasionally. There's a problem called the knapsack problem, which is a very classic optimization problem. It looks not that dissimilar to a queuing problem that we have where we theoretically tesselate all of the potential groceries into our shopping baskets. As you are clicking add to basket, we are doing that tessellation live so that we can maximize the efficiency of the traveling salesman problem, uh that is the last mile grocery logistics. And at the point that we've tried to formulate this problem into a quantum problem, the number of cubits we need is in the millions. And uh at the moment, D-Wave machines are in the thousands and maybe there's some governments out there with uh machines which are far more powerful. But for me, when we've dabbled in it, it looks very distant at the moment.
M: Not yet, for sure.
R: Not yet.
M: We're talking time frames of years, decades?
R: So I'm happy to, I mean, depending on who you talk to, quantum computing is tomorrow or 300 years away.
M: Right, so somewhere between.
R: Somewhere between there.
M: All right, fantastic. Well, thank you very much.